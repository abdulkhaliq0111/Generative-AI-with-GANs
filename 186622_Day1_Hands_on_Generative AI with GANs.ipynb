{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "## Install and import the PyTorch libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==2.0.0+cpu\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torch-2.0.0%2Bcpu-cp311-cp311-win_amd64.whl (174.0 MB)\n",
      "Collecting torchvision==0.15.0+cpu\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.15.0%2Bcpu-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Collecting torchaudio==2.0.0\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.0%2Bcu118-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     --------------- ------------------------ 1.0/2.5 MB 20.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 MB 30.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 19.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from torch==2.0.0+cpu) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from torch==2.0.0+cpu) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from torch==2.0.0+cpu) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from torch==2.0.0+cpu) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from torch==2.0.0+cpu) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from torchvision==0.15.0+cpu) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from torchvision==0.15.0+cpu) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from torchvision==0.15.0+cpu) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from jinja2->torch==2.0.0+cpu) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.0+cpu) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.0+cpu) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.0+cpu) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from requests->torchvision==0.15.0+cpu) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from sympy->torch==2.0.0+cpu) (1.3.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.0.0+cpu torchaudio-2.0.0+cu118 torchvision-0.15.0+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.0+cpu torchvision==0.15.0+cpu torchaudio==2.0.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported - ready to use PyTorch 2.0.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as td\n",
    "\n",
    "# Set random seed for reproducability\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "## Basic operations with Pytorch\n",
    "\n",
    "1.Tensors creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4194, 0.5529, 0.9527, 0.0362],\n",
      "        [0.1852, 0.3734, 0.3051, 0.9320],\n",
      "        [0.1759, 0.2698, 0.1507, 0.0317]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of shape (3, 4) filled with random numbers\n",
    "random_tensor = torch.rand((3, 4))\n",
    "# Create a tensor of shape (2, 3) filled with zeroes\n",
    "zero_tensor = torch.zeros((2, 3))\n",
    "# Create a tensor of shape (3, 3) filled with ones\n",
    "one_tensor = torch.ones((3, 3))\n",
    "\n",
    "print(random_tensor)\n",
    "print(zero_tensor)\n",
    "print(one_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tensors Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.2081, 0.9298],\n",
      "        [0.7231, 0.7423]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.5263, 0.2437],\n",
      "        [0.5846, 0.0332]])\n",
      "\n",
      "Sum of Tensor A and Tensor B:\n",
      "tensor([[0.7344, 1.1735],\n",
      "        [1.3077, 0.7755]])\n",
      "\n",
      "Element-wise Product of Tensor A and Tensor B:\n",
      "tensor([[0.1095, 0.2266],\n",
      "        [0.4227, 0.0246]])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors of shape (2, 2) filled with random numbers\n",
    "tensor_a = torch.rand((2, 2))\n",
    "tensor_b = torch.rand((2, 2))\n",
    "\n",
    "# Add the two tensors\n",
    "tensor_sum = torch.add(tensor_a, tensor_b)\n",
    "\n",
    "# Multiply the two tensors element-wise\n",
    "tensor_product = torch.mul(tensor_a, tensor_b)\n",
    "\n",
    "print(\"Tensor A:\")\n",
    "print(tensor_a)\n",
    "\n",
    "print(\"\\nTensor B:\")\n",
    "print(tensor_b)\n",
    "\n",
    "print(\"\\nSum of Tensor A and Tensor B:\")\n",
    "print(tensor_sum)\n",
    "\n",
    "print(\"\\nElement-wise Product of Tensor A and Tensor B:\")\n",
    "print(tensor_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.5932, 0.1123, 0.1535],\n",
      "        [0.2417, 0.7262, 0.7011]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.2038, 0.6511],\n",
      "        [0.7745, 0.4369],\n",
      "        [0.5191, 0.6159]])\n",
      "\n",
      "Matrix Product of Tensor A and Tensor B:\n",
      "tensor([[0.2876, 0.5298],\n",
      "        [0.9757, 0.9064]])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors of shapes (2, 3) and (3, 2) filled with random numbers\n",
    "tensor_a = torch.rand((2, 3))\n",
    "tensor_b = torch.rand((3, 2))\n",
    "\n",
    "# Perform matrix multiplication\n",
    "tensor_product = torch.matmul(tensor_a, tensor_b)\n",
    "\n",
    "print(\"Tensor A:\")\n",
    "print(tensor_a)\n",
    "\n",
    "print(\"\\nTensor B:\")\n",
    "print(tensor_b)\n",
    "\n",
    "print(\"\\nMatrix Product of Tensor A and Tensor B:\")\n",
    "print(tensor_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tensor Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor (2x3):\n",
      "tensor([[0.1100, 0.2121, 0.9704],\n",
      "        [0.8369, 0.2820, 0.3742]])\n",
      "\n",
      "Reshaped Tensor (3x2):\n",
      "tensor([[0.1100, 0.2121],\n",
      "        [0.9704, 0.8369],\n",
      "        [0.2820, 0.3742]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Reshape a tensor of shape (2, 3) to (3, 2)\n",
    "tensor_a = torch.rand((2, 3))\n",
    "reshaped_tensor = tensor_a.reshape(3, 2)\n",
    "\n",
    "print(\"Original Tensor (2x3):\")\n",
    "print(tensor_a)\n",
    "\n",
    "print(\"\\nReshaped Tensor (3x2):\")\n",
    "print(reshaped_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tensor B (2x2):\n",
      "tensor([[0.0237, 0.4910],\n",
      "        [0.1235, 0.1143]])\n",
      "\n",
      "Tensor C (2x2):\n",
      "tensor([[0.4725, 0.5751],\n",
      "        [0.2952, 0.7967]])\n",
      "\n",
      "Concatenated along dimension 0:\n",
      "tensor([[0.0237, 0.4910],\n",
      "        [0.1235, 0.1143],\n",
      "        [0.4725, 0.5751],\n",
      "        [0.2952, 0.7967]])\n",
      "\n",
      "Concatenated along dimension 1:\n",
      "tensor([[0.0237, 0.4910, 0.4725, 0.5751],\n",
      "        [0.1235, 0.1143, 0.2952, 0.7967]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate two tensors of shape (2, 2) along dimension 0 and dimension 1\n",
    "tensor_b = torch.rand((2, 2))\n",
    "tensor_c = torch.rand((2, 2))\n",
    "\n",
    "concatenated_dim0 = torch.cat((tensor_b, tensor_c), dim=0)\n",
    "concatenated_dim1 = torch.cat((tensor_b, tensor_c), dim=1)\n",
    "\n",
    "print(\"\\nTensor B (2x2):\")\n",
    "print(tensor_b)\n",
    "\n",
    "print(\"\\nTensor C (2x2):\")\n",
    "print(tensor_c)\n",
    "\n",
    "print(\"\\nConcatenated along dimension 0:\")\n",
    "print(concatenated_dim0)\n",
    "\n",
    "print(\"\\nConcatenated along dimension 1:\")\n",
    "print(concatenated_dim1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Tensor (4x4):\n",
      "tensor([[0.1957, 0.9537, 0.8426, 0.0784],\n",
      "        [0.3756, 0.5226, 0.5730, 0.6186],\n",
      "        [0.6962, 0.5300, 0.2560, 0.7366],\n",
      "        [0.0204, 0.2036, 0.3748, 0.2564]])\n",
      "\n",
      "Split Tensors (2x4):\n",
      "Split Tensor 1:\n",
      "tensor([[0.1957, 0.9537, 0.8426, 0.0784],\n",
      "        [0.3756, 0.5226, 0.5730, 0.6186]])\n",
      "Split Tensor 2:\n",
      "tensor([[0.6962, 0.5300, 0.2560, 0.7366],\n",
      "        [0.0204, 0.2036, 0.3748, 0.2564]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split a tensor of shape (4, 4) into two tensors of shape (2, 4)\n",
    "tensor_d = torch.rand((4, 4))\n",
    "split_tensors = torch.split(tensor_d, 2)\n",
    "\n",
    "print(\"\\nOriginal Tensor (4x4):\")\n",
    "print(tensor_d)\n",
    "\n",
    "print(\"\\nSplit Tensors (2x4):\")\n",
    "for i, split_tensor in enumerate(split_tensors):\n",
    "    print(f\"Split Tensor {i+1}:\")\n",
    "    print(split_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_15868\\1496640392.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  wine = wine.append(wine)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoids</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280_315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>WineVariety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>14.34</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.70</td>\n",
       "      <td>25.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.96</td>\n",
       "      <td>660</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>13.07</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.10</td>\n",
       "      <td>15.5</td>\n",
       "      <td>98</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.64</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>12.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>2.00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.12</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>11.76</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.92</td>\n",
       "      <td>20.0</td>\n",
       "      <td>103</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.50</td>\n",
       "      <td>607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>116</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>425</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>11.84</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.23</td>\n",
       "      <td>18.0</td>\n",
       "      <td>112</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.52</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>12.22</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.94</td>\n",
       "      <td>19.0</td>\n",
       "      <td>92</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.02</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>13.08</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.36</td>\n",
       "      <td>21.5</td>\n",
       "      <td>113</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.14</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.33</td>\n",
       "      <td>550</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>11.61</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.70</td>\n",
       "      <td>20.0</td>\n",
       "      <td>94</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.26</td>\n",
       "      <td>680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_acid   Ash  Alcalinity  Magnesium  Phenols  Flavanoids  \\\n",
       "158    14.34        1.68  2.70        25.0         98     2.80        1.31   \n",
       "38     13.07        1.50  2.10        15.5         98     2.40        2.64   \n",
       "80     12.00        0.92  2.00        19.0         86     2.42        2.26   \n",
       "4      13.24        2.59  2.87        21.0        118     2.80        2.69   \n",
       "112    11.76        2.68  2.92        20.0        103     1.75        2.03   \n",
       "152    13.11        1.90  2.75        25.5        116     2.20        1.28   \n",
       "77     11.84        2.89  2.23        18.0        112     1.72        1.32   \n",
       "108    12.22        1.29  1.94        19.0         92     2.36        2.04   \n",
       "149    13.08        3.90  2.36        21.5        113     1.41        1.39   \n",
       "109    11.61        1.35  2.70        20.0         94     2.74        2.92   \n",
       "\n",
       "     Nonflavanoids  Proanthocyanins  Color_intensity   Hue  \\\n",
       "158           0.53             2.70            13.00  0.57   \n",
       "38            0.28             1.37             3.70  1.18   \n",
       "80            0.30             1.43             2.50  1.38   \n",
       "4             0.39             1.82             4.32  1.04   \n",
       "112           0.60             1.05             3.80  1.23   \n",
       "152           0.26             1.56             7.10  0.61   \n",
       "77            0.43             0.95             2.65  0.96   \n",
       "108           0.39             2.08             2.70  0.86   \n",
       "149           0.34             1.14             9.40  0.57   \n",
       "109           0.29             2.49             2.65  0.96   \n",
       "\n",
       "     OD280_315_of_diluted_wines  Proline  WineVariety  \n",
       "158                        1.96      660            2  \n",
       "38                         2.69     1020            0  \n",
       "80                         3.12      278            1  \n",
       "4                          2.93      735            0  \n",
       "112                        2.50      607            1  \n",
       "152                        1.33      425            2  \n",
       "77                         2.52      500            1  \n",
       "108                        3.02      312            1  \n",
       "149                        1.33      550            2  \n",
       "109                        3.26      680            1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the training dataset (excluding rows with null values)\n",
    "wine = pd.read_csv('wine.csv').dropna()\n",
    "\n",
    "\n",
    "\n",
    "# The dataset is too small to be useful for deep learning\n",
    "# # So we'll oversample it to increase its size\n",
    "for i in range(1,3):\n",
    "    wine = wine.append(wine)\n",
    "\n",
    "# Display a random sample of 10 observations\n",
    "sample = wine.sample(10)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is common in a supervised learning problem, we'll split the dataset into a set of records with which to train the model, and a smaller set with which to validate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 498, Test Set: 214 \n",
      "\n",
      "Sample of features and labels:\n",
      "[1.348e+01 1.670e+00 2.640e+00 2.250e+01 8.900e+01 2.600e+00 1.100e+00\n",
      " 5.200e-01 2.290e+00 1.175e+01 5.700e-01 1.780e+00 6.200e+02]\n",
      "******\n",
      "2\n",
      "[1.371e+01 5.650e+00 2.450e+00 2.050e+01 9.500e+01 1.680e+00 6.100e-01\n",
      " 5.200e-01 1.060e+00 7.700e+00 6.400e-01 1.740e+00 7.400e+02]\n",
      "******\n",
      "2\n",
      "[1.233e+01 9.900e-01 1.950e+00 1.480e+01 1.360e+02 1.900e+00 1.850e+00\n",
      " 3.500e-01 2.760e+00 3.400e+00 1.060e+00 2.310e+00 7.500e+02]\n",
      "******\n",
      "1\n",
      "[ 12.69   1.53   2.26  20.7   80.     1.38   1.46   0.58   1.62   3.05\n",
      "   0.96   2.06 495.  ]\n",
      "******\n",
      "1\n",
      "[ 12.53   5.51   2.64  25.    96.     1.79   0.6    0.63   1.1    5.\n",
      "   0.82   1.69 515.  ]\n",
      "******\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = wine.columns[:-1]\n",
    "label =  wine.columns[-1]\n",
    "   \n",
    "# Split data 70%-30% into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine[features].values,\n",
    "                                                    wine[label].values,\n",
    "                                                    test_size=0.30,\n",
    "                                                    random_state=0)\n",
    "\n",
    "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
    "print(\"Sample of features and labels:\")\n",
    "\n",
    "# Take a look at the first 25 training features and corresponding labels\n",
    "for n in range(0,5):\n",
    "    print(x_train[n])\n",
    "    print(\"******\")\n",
    "    print(y_train[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_varieties = wine[label].unique()\n",
    "wine_varieties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Building  a neural network\n",
    "\n",
    "Now we're ready to define our neural network. In this case, we'll create a network that consists of 3 fully-connected layers:\n",
    "* An input layer that receives an input value for each feature and applies a *ReLU* activation function.\n",
    "* A hidden layer that receives ten inputs and applies a *ReLU* activation function.\n",
    "* An output layer that generates a non-negative numeric output for each wine variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WineNet(\n",
      "  (fc1): Linear(in_features=13, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn.init as init# Number of hidden layer nodes\n",
    "hl = 50\n",
    "\n",
    "# Define the neural network\n",
    "class WineNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WineNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(features), hl)\n",
    "        self.fc2 = nn.Linear(hl, hl)\n",
    "        self.fc3 = nn.Linear(hl, len(wine_varieties))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Create a model instance from the network\n",
    "model = WineNet()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for PyTorch\n",
    "\n",
    "PyTorch makes use of *data loaders* to load training and validation data in batches. We've already loaded the data into numpy arrays, but we need to wrap those in PyTorch datasets (in which the data is converted to PyTorch *tensor* objects) and create loaders to read batches from those datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train.mean()) / x_train.std()\n",
    "x_test = (x_test - x_test.mean()) / x_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to load data\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset and loader for the training data and labels\n",
    "train_x = torch.Tensor(x_train).float()\n",
    "train_y = torch.Tensor(y_train).long()\n",
    "train_ds = td.TensorDataset(train_x,train_y)\n",
    "train_loader = td.DataLoader(train_ds, batch_size=20,\n",
    "    shuffle=False, num_workers=1)\n",
    "\n",
    "# Create a dataset and loader for the test data and labels\n",
    "test_x = torch.Tensor(x_test).float()\n",
    "test_y = torch.Tensor(y_test).long()\n",
    "test_ds = td.TensorDataset(test_x,test_y)\n",
    "test_loader = td.DataLoader(test_ds, batch_size=30,\n",
    "    shuffle=False, num_workers=1)\n",
    "print('Ready to load data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "To train the model, we need to repeatedly feed the training values forward through the network, use a loss function to calculate the loss, use an optimizer to backpropagate the weight and bias value adjustments, and validate the model using the test data we withheld.\n",
    "\n",
    "To do this, we'll create a function to train and optimize the model, and function to test the model. Then we'll call these functions iteratively over 50 epochs, logging the loss and accuracy statistics for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, tensor in enumerate(data_loader):\n",
    "        data, target = tensor\n",
    "        #feedforward\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_criteria(out, target)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #Return average loss\n",
    "    avg_loss = train_loss / (batch+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss\n",
    "           \n",
    "            \n",
    "def test(model, data_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for batch, tensor in enumerate(data_loader):\n",
    "            batch_count += 1\n",
    "            data, target = tensor\n",
    "            # Get the predictions\n",
    "            out = model(data)\n",
    "\n",
    "            # calculate the loss\n",
    "            test_loss += loss_criteria(out, target).item()\n",
    "\n",
    "            # Calculate the accuracy\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "            \n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss/batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training set: Average loss: 1.044696\n",
      "Validation set: Average loss: 1.023205, Accuracy: 99/214 (46%)\n",
      "\n",
      "Epoch: 2\n",
      "Training set: Average loss: 0.983421\n",
      "Validation set: Average loss: 0.945795, Accuracy: 133/214 (62%)\n",
      "\n",
      "Epoch: 3\n",
      "Training set: Average loss: 0.897740\n",
      "Validation set: Average loss: 0.845728, Accuracy: 140/214 (65%)\n",
      "\n",
      "Epoch: 4\n",
      "Training set: Average loss: 0.804170\n",
      "Validation set: Average loss: 0.754709, Accuracy: 141/214 (66%)\n",
      "\n",
      "Epoch: 5\n",
      "Training set: Average loss: 0.726600\n",
      "Validation set: Average loss: 0.685564, Accuracy: 142/214 (66%)\n",
      "\n",
      "Epoch: 6\n",
      "Training set: Average loss: 0.673923\n",
      "Validation set: Average loss: 0.640400, Accuracy: 142/214 (66%)\n",
      "\n",
      "Epoch: 7\n",
      "Training set: Average loss: 0.641952\n",
      "Validation set: Average loss: 0.611273, Accuracy: 145/214 (68%)\n",
      "\n",
      "Epoch: 8\n",
      "Training set: Average loss: 0.623433\n",
      "Validation set: Average loss: 0.594327, Accuracy: 150/214 (70%)\n",
      "\n",
      "Epoch: 9\n",
      "Training set: Average loss: 0.611092\n",
      "Validation set: Average loss: 0.581340, Accuracy: 152/214 (71%)\n",
      "\n",
      "Epoch: 10\n",
      "Training set: Average loss: 0.602798\n",
      "Validation set: Average loss: 0.571685, Accuracy: 149/214 (70%)\n",
      "\n",
      "Epoch: 11\n",
      "Training set: Average loss: 0.596030\n",
      "Validation set: Average loss: 0.563093, Accuracy: 152/214 (71%)\n",
      "\n",
      "Epoch: 12\n",
      "Training set: Average loss: 0.590588\n",
      "Validation set: Average loss: 0.556504, Accuracy: 153/214 (71%)\n",
      "\n",
      "Epoch: 13\n",
      "Training set: Average loss: 0.586011\n",
      "Validation set: Average loss: 0.550622, Accuracy: 152/214 (71%)\n",
      "\n",
      "Epoch: 14\n",
      "Training set: Average loss: 0.582200\n",
      "Validation set: Average loss: 0.546073, Accuracy: 151/214 (71%)\n",
      "\n",
      "Epoch: 15\n",
      "Training set: Average loss: 0.578850\n",
      "Validation set: Average loss: 0.541989, Accuracy: 155/214 (72%)\n",
      "\n",
      "Epoch: 16\n",
      "Training set: Average loss: 0.575831\n",
      "Validation set: Average loss: 0.538048, Accuracy: 155/214 (72%)\n",
      "\n",
      "Epoch: 17\n",
      "Training set: Average loss: 0.573030\n",
      "Validation set: Average loss: 0.535349, Accuracy: 158/214 (74%)\n",
      "\n",
      "Epoch: 18\n",
      "Training set: Average loss: 0.570634\n",
      "Validation set: Average loss: 0.532855, Accuracy: 160/214 (75%)\n",
      "\n",
      "Epoch: 19\n",
      "Training set: Average loss: 0.568382\n",
      "Validation set: Average loss: 0.530351, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 20\n",
      "Training set: Average loss: 0.566248\n",
      "Validation set: Average loss: 0.527876, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 21\n",
      "Training set: Average loss: 0.564213\n",
      "Validation set: Average loss: 0.525504, Accuracy: 160/214 (75%)\n",
      "\n",
      "Epoch: 22\n",
      "Training set: Average loss: 0.562407\n",
      "Validation set: Average loss: 0.523902, Accuracy: 160/214 (75%)\n",
      "\n",
      "Epoch: 23\n",
      "Training set: Average loss: 0.560816\n",
      "Validation set: Average loss: 0.522724, Accuracy: 160/214 (75%)\n",
      "\n",
      "Epoch: 24\n",
      "Training set: Average loss: 0.559191\n",
      "Validation set: Average loss: 0.520654, Accuracy: 160/214 (75%)\n",
      "\n",
      "Epoch: 25\n",
      "Training set: Average loss: 0.557747\n",
      "Validation set: Average loss: 0.518961, Accuracy: 160/214 (75%)\n",
      "\n",
      "Epoch: 26\n",
      "Training set: Average loss: 0.556465\n",
      "Validation set: Average loss: 0.517846, Accuracy: 160/214 (75%)\n",
      "\n",
      "Epoch: 27\n",
      "Training set: Average loss: 0.555324\n",
      "Validation set: Average loss: 0.516769, Accuracy: 160/214 (75%)\n",
      "\n",
      "Epoch: 28\n",
      "Training set: Average loss: 0.554118\n",
      "Validation set: Average loss: 0.515441, Accuracy: 160/214 (75%)\n",
      "\n",
      "Epoch: 29\n",
      "Training set: Average loss: 0.553137\n",
      "Validation set: Average loss: 0.514301, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 30\n",
      "Training set: Average loss: 0.552272\n",
      "Validation set: Average loss: 0.513708, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 31\n",
      "Training set: Average loss: 0.551454\n",
      "Validation set: Average loss: 0.512686, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 32\n",
      "Training set: Average loss: 0.550597\n",
      "Validation set: Average loss: 0.511937, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 33\n",
      "Training set: Average loss: 0.549811\n",
      "Validation set: Average loss: 0.511108, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 34\n",
      "Training set: Average loss: 0.549156\n",
      "Validation set: Average loss: 0.510498, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 35\n",
      "Training set: Average loss: 0.548510\n",
      "Validation set: Average loss: 0.509235, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 36\n",
      "Training set: Average loss: 0.547729\n",
      "Validation set: Average loss: 0.508726, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 37\n",
      "Training set: Average loss: 0.547151\n",
      "Validation set: Average loss: 0.507650, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 38\n",
      "Training set: Average loss: 0.546546\n",
      "Validation set: Average loss: 0.507284, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 39\n",
      "Training set: Average loss: 0.546078\n",
      "Validation set: Average loss: 0.506773, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 40\n",
      "Training set: Average loss: 0.545533\n",
      "Validation set: Average loss: 0.506182, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 41\n",
      "Training set: Average loss: 0.544836\n",
      "Validation set: Average loss: 0.505446, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 42\n",
      "Training set: Average loss: 0.544191\n",
      "Validation set: Average loss: 0.504894, Accuracy: 164/214 (77%)\n",
      "\n",
      "Epoch: 43\n",
      "Training set: Average loss: 0.543579\n",
      "Validation set: Average loss: 0.504511, Accuracy: 164/214 (77%)\n",
      "\n",
      "Epoch: 44\n",
      "Training set: Average loss: 0.542996\n",
      "Validation set: Average loss: 0.504700, Accuracy: 164/214 (77%)\n",
      "\n",
      "Epoch: 45\n",
      "Training set: Average loss: 0.542521\n",
      "Validation set: Average loss: 0.504000, Accuracy: 164/214 (77%)\n",
      "\n",
      "Epoch: 46\n",
      "Training set: Average loss: 0.541836\n",
      "Validation set: Average loss: 0.502937, Accuracy: 164/214 (77%)\n",
      "\n",
      "Epoch: 47\n",
      "Training set: Average loss: 0.541123\n",
      "Validation set: Average loss: 0.502140, Accuracy: 164/214 (77%)\n",
      "\n",
      "Epoch: 48\n",
      "Training set: Average loss: 0.540544\n",
      "Validation set: Average loss: 0.501410, Accuracy: 164/214 (77%)\n",
      "\n",
      "Epoch: 49\n",
      "Training set: Average loss: 0.539797\n",
      "Validation set: Average loss: 0.500948, Accuracy: 161/214 (75%)\n",
      "\n",
      "Epoch: 50\n",
      "Training set: Average loss: 0.539097\n",
      "Validation set: Average loss: 0.500158, Accuracy: 161/214 (75%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# We'll track metrics for each epoch in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "# Train over 50 epochs\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # print the epoch number\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    \n",
    "    # Feed training data into the model to optimize the weights\n",
    "    train_loss = train(model, train_loader, optimizer)\n",
    "    \n",
    "    # Feed the test data into the model to check its performance\n",
    "    test_loss = test(model, test_loader)\n",
    "    \n",
    "    # Log the metrics for this epoch\n",
    "    epoch_nums.append(epoch)\n",
    "    training_loss.append(train_loss)\n",
    "    validation_loss.append(test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
